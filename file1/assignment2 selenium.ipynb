{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f229446",
   "metadata": {},
   "source": [
    "# Q1: In this question you have to scrape data using the filters available on the webpage You have to use the location and \n",
    "salary filter. \n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results. \n",
    "You have to scrape the job-title, job-location, company name, experience required. \n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs \n",
    "The task will be done as shown in the below steps: \n",
    "1. first get the web page https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field. \n",
    "3. Then click the search button. \n",
    "4. Then apply the location filter and salary filter by checking the respective boxes \n",
    "5. Then scrape the data for the first 10 jobs results you get. \n",
    "6. Finally create a dataframe of the scraped data. \n",
    "Note: All of the above steps have to be done in code. No step is to be done manuall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7124213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0d0d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a5268b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the naukri page on automated chrome browser \n",
    "\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb19b447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and location as required in the question\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64bebef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "location= driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location.send_keys('Delhi/NCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f91d56c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b77236ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping job title from the given page \n",
    "job_title = []\n",
    "title_tags = driver.find_elements(By.XPATH,'//div[@class=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple \"]/div/a')\n",
    "for i in title_tags:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "\n",
    "# Scraping job location from the given page \n",
    "\n",
    "job_location = []\n",
    "location_tags = driver.find_elements(By.XPATH,'//span[@class=\"locWdth\"]')\n",
    "for i in location_tags:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# Scraping company name from the given page \n",
    "company_name = []\n",
    "name_tags = driver.find_elements(By.XPATH,'//div[@class=\" row2\"]/span/a[1]')\n",
    "for i in name_tags:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# Scraping job experience from the given page\n",
    "\n",
    "experience_required = []\n",
    "\n",
    "experience_tags = driver.find_elements(By.XPATH,'//span[@class=\"expwdth\"]')\n",
    "for i in experience_tags:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebe41651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "#check the length of each element\n",
    "\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2dac927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "df=pd.DataFrame({})\n",
    "df['Title']=job_title[:10]\n",
    "df['Location']=job_location[:10]\n",
    "df['Company_name']=company_name[:10]\n",
    "df['Experience']=experience_required[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06544cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist, Reporting</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Coursera</td>\n",
       "      <td>6-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Ford</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Kashsam Data Solutions</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NLP Data Scientist - Real World Data (RWD)</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Agilite Global Solutions</td>\n",
       "      <td>7-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analytics-Corporate HR</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Tata Communications</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DS - NLP Expert</td>\n",
       "      <td>Hyderabad, Telangana, Gurugram, Haryana, Banga...</td>\n",
       "      <td>Genpact</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist II</td>\n",
       "      <td>Greater Noida, Bengaluru</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Scienaptic Systems</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NLP Data Scientist - Real World Data (RWD)</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Agilite</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lead MLOps Engineer</td>\n",
       "      <td>Noida, Pune</td>\n",
       "      <td>R Systems International</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Title  \\\n",
       "0            Senior Data Scientist, Reporting   \n",
       "1                              Data Scientist   \n",
       "2                              Data Scientist   \n",
       "3  NLP Data Scientist - Real World Data (RWD)   \n",
       "4                 Data Analytics-Corporate HR   \n",
       "5                             DS - NLP Expert   \n",
       "6                           Data Scientist II   \n",
       "7                              Data Scientist   \n",
       "8  NLP Data Scientist - Real World Data (RWD)   \n",
       "9                         Lead MLOps Engineer   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...   \n",
       "1  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...   \n",
       "2  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...   \n",
       "3  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...   \n",
       "4  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...   \n",
       "5  Hyderabad, Telangana, Gurugram, Haryana, Banga...   \n",
       "6                           Greater Noida, Bengaluru   \n",
       "7  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...   \n",
       "8  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...   \n",
       "9                                        Noida, Pune   \n",
       "\n",
       "               Company_name Experience  \n",
       "0                  Coursera    6-7 Yrs  \n",
       "1                      Ford    3-6 Yrs  \n",
       "2    Kashsam Data Solutions    3-7 Yrs  \n",
       "3  Agilite Global Solutions    7-8 Yrs  \n",
       "4       Tata Communications    3-6 Yrs  \n",
       "5                   Genpact   6-11 Yrs  \n",
       "6                 Honeywell    4-6 Yrs  \n",
       "7        Scienaptic Systems    2-7 Yrs  \n",
       "8                   Agilite    3-8 Yrs  \n",
       "9   R Systems International    5-8 Yrs  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be943a2",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the \n",
    "job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the searchbutton. \n",
    "4. Then scrape the data for the first 10 jobs results you get. \n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "915e9734",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec3d4f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the shine page on automated chrome browser \n",
    "\n",
    "driver.get(\"https://www.shine.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4915f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering job as required in the question\n",
    "jobtitle_skill = driver.find_element(By.CLASS_NAME,\"form-control  \")\n",
    "jobtitle_skill.send_keys('Data Analyst')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cec174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "location= driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d176125",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"searchForm_btnWrap_advance__VYBHN\")\n",
    "search.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b702dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the empty list for each element\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f0ed7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Analyst Recruitment',\n",
       " 'Data Analyst Recruitment',\n",
       " 'Data Analyst (Power BI, Python, SQL)- Internal Audit do ...',\n",
       " 'Clinical Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Engineer Ii',\n",
       " 'Data Governance Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Engineer Ii',\n",
       " 'Hiring For Data Analyst']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping job title from the given page \n",
    "title_tags = driver.find_elements(By.XPATH,'//strong[@class=\"jobCard_pReplaceH2__xWmHg\"]') \n",
    "for i in title_tags:\n",
    "    if i.text is None:\n",
    "        job_title.append('Not')\n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "job_title[:10]\n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4849fcbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['radhika enterprises',\n",
       " 'radhika enterprises',\n",
       " 'talent leads hr solutions pvt ltd',\n",
       " 'techno endura',\n",
       " 'sahast sales corporation',\n",
       " 'v-tech data outsourcing',\n",
       " 'white horse manpower consultancy (p...',\n",
       " 'sahast sales corporation',\n",
       " 'v-tech data outsourcing',\n",
       " 'radhika enterprises']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "# Scraping company name from the given page \n",
    "\n",
    "name_tags = driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]')\n",
    "for i in name_tags:\n",
    "    if i.text is None:\n",
    "        company_name.append('Not')\n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name[:10]\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebd44a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore\\n+12',\n",
       " 'Bangalore\\n+12',\n",
       " 'Bangalore',\n",
       " 'Bangalore\\n+6',\n",
       " 'Bangalore\\n+9',\n",
       " 'Bangalore\\n+9',\n",
       " 'Bangalore',\n",
       " 'Bangalore\\n+9',\n",
       " 'Bangalore\\n+9',\n",
       " 'Bangalore\\n+12']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping job location from the given page \n",
    "\n",
    "location_tags = driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location_tags:\n",
    "    if i.text is None:\n",
    "        job_location.append('Not')\n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "job_location[:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cab17db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0 to 4 Yrs',\n",
       " '0 to 4 Yrs',\n",
       " '3 to 8 Yrs',\n",
       " '0 to 1 Yr',\n",
       " '12 to 22 Yrs',\n",
       " '0 to 1 Yr',\n",
       " '5 to 8 Yrs',\n",
       " '12 to 22 Yrs',\n",
       " '0 to 1 Yr',\n",
       " '0 to 4 Yrs']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "   \n",
    "# Scraping job experience from the given page\n",
    "\n",
    "experience_tags = driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in experience_tags:\n",
    "    if i.text is None:\n",
    "        experience_required.append('Not')\n",
    "    else:\n",
    "        experience_required.append(i.text)\n",
    "experience_required[:10]\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efac840b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8053633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Title']=job_title[:10]\n",
    "df['Location']=job_location[:10]\n",
    "df['Company_name']=company_name[:10]\n",
    "df['Experience']=experience_required[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e5ca62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst Recruitment</td>\n",
       "      <td>Bangalore\\n+12</td>\n",
       "      <td>radhika enterprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst Recruitment</td>\n",
       "      <td>Bangalore\\n+12</td>\n",
       "      <td>radhika enterprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst (Power BI, Python, SQL)- Internal...</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>talent leads hr solutions pvt ltd</td>\n",
       "      <td>3 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Bangalore\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>sahast sales corporation</td>\n",
       "      <td>12 to 22 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Engineer Ii</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>v-tech data outsourcing</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Governance Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>white horse manpower consultancy (p...</td>\n",
       "      <td>5 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>sahast sales corporation</td>\n",
       "      <td>12 to 22 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Engineer Ii</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>v-tech data outsourcing</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring For Data Analyst</td>\n",
       "      <td>Bangalore\\n+12</td>\n",
       "      <td>radhika enterprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Location  \\\n",
       "0                           Data Analyst Recruitment  Bangalore\\n+12   \n",
       "1                           Data Analyst Recruitment  Bangalore\\n+12   \n",
       "2  Data Analyst (Power BI, Python, SQL)- Internal...       Bangalore   \n",
       "3                              Clinical Data Analyst   Bangalore\\n+6   \n",
       "4                                       Data Analyst   Bangalore\\n+9   \n",
       "5                                   Data Engineer Ii   Bangalore\\n+9   \n",
       "6                            Data Governance Analyst       Bangalore   \n",
       "7                                       Data Analyst   Bangalore\\n+9   \n",
       "8                                   Data Engineer Ii   Bangalore\\n+9   \n",
       "9                            Hiring For Data Analyst  Bangalore\\n+12   \n",
       "\n",
       "                             Company_name    Experience  \n",
       "0                     radhika enterprises    0 to 4 Yrs  \n",
       "1                     radhika enterprises    0 to 4 Yrs  \n",
       "2       talent leads hr solutions pvt ltd    3 to 8 Yrs  \n",
       "3                           techno endura     0 to 1 Yr  \n",
       "4                sahast sales corporation  12 to 22 Yrs  \n",
       "5                 v-tech data outsourcing     0 to 1 Yr  \n",
       "6  white horse manpower consultancy (p...    5 to 8 Yrs  \n",
       "7                sahast sales corporation  12 to 22 Yrs  \n",
       "8                 v-tech data outsourcing     0 to 1 Yr  \n",
       "9                     radhika enterprises    0 to 4 Yrs  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142ac884",
   "metadata": {},
   "source": [
    "# Q3: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/product\u0002reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=F\n",
    "LIPKART\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews.\n",
    "Note: All the stepsrequired during scraping should be done through code only and not manuall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e18447fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c8325d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the shine page on automated chrome browser \n",
    "\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b372b14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping rating from the given page \n",
    "rating=[]\n",
    "\n",
    "rating_tags = driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in rating_tags:\n",
    "    ra=i.text\n",
    "    rating.append(ra)\n",
    "    \n",
    "# Scraping rating from the given page \n",
    "review=[]\n",
    "\n",
    "review_tags = driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "for i in review_tags:\n",
    "    ra=i.text\n",
    "    review.append(ra)\n",
    "\n",
    "# Scraping rating from the given page \n",
    "full_review=[]\n",
    "\n",
    "fullreview_tags = driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "for i in fullreview_tags:\n",
    "    ra=i.text\n",
    "    full_review.append(ra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63bbb4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(rating),len(review),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63fb422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=[]\n",
    "review=[]\n",
    "full_review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e85846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrap the rating_tags\n",
    "start=0\n",
    "end=9\n",
    "for page in range(start,end):\n",
    "    tags=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in tags:\n",
    "        rating.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]')\n",
    "    next_button.click()\n",
    "    \n",
    "rating[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fe8f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scrap the review_tags\n",
    "start=0\n",
    "end=9\n",
    "for page in range(start,end):\n",
    "    r_tags=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in r_tags:\n",
    "        review.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]')\n",
    "    next_button.click()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5926c3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# Scrap the fullreview_tags\n",
    "start=0\n",
    "end=9\n",
    "for page in range(start,end):\n",
    "    fr_tags=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in fr_tags:\n",
    "        full_review.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]')\n",
    "    next_button.click()\n",
    "print(full_review)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132dd998",
   "metadata": {},
   "source": [
    "# Q4: Scrape data forfirst 100 sneakers you find whenyouvisitflipkart.com and search for “sneakers” inthe search\n",
    "field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the above attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9746f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09feae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the flipkart page on automated chrome browser \n",
    "\n",
    "driver.get(\"https://www.flipkart.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fbc8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering brand as required in the question\n",
    "product = driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/div/input\")\n",
    "product.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181ea791",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf5d44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_name = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ef19a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the brand from the given page \n",
    "brand_tags = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tags:\n",
    "    title=i.text\n",
    "    brand_name.append(title)\n",
    "brand_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babc9bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(brand_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8444c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_description = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f432882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping description from the given page \n",
    "\n",
    "description_tags = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "for i in description_tags:\n",
    "    description=i.text\n",
    "    product_description.append(description)\n",
    "product_description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e41689",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(product_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b30b06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6ab36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping price from the given page \n",
    "\n",
    "price_tags = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in price_tags:\n",
    "    rate=i.text\n",
    "    price.append(rate)\n",
    "price\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57fb875",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1626e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2aa9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the brands from multiple pages\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    brand=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand:\n",
    "        brand_name.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa3bf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(brand_name[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46bcc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de1f216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping description from multiple pages\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    description=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in description:\n",
    "        product_description.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd98fde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(product_description[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7783e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a04c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping price from multiple pages\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    rate=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in rate:\n",
    "        price.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "price[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764e156c",
   "metadata": {},
   "source": [
    "# Q5: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU\n",
    "Type filter to “Intel Core i7” as shown in the below image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094ef76a",
   "metadata": {},
   "source": [
    "# Aftersetting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cd01e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea8f065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the amazon page on automated chrome browser \n",
    "\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66a378",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand= driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "brand.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35673cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"nav-right\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4e6402",
   "metadata": {},
   "outputs": [],
   "source": [
    "check=driver.find_element(By.XPATH,'//i[@class=\"a-icon a-icon-checkbox\"]')\n",
    "check.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69824b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23288ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping title from the given page \n",
    "\n",
    "title_tags = driver.find_elements(By.XPATH,'//SPAN[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in title_tags:\n",
    "    title=i.text\n",
    "    Title.append(title)\n",
    "print(Title[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8adff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d4f12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping rating from the given page \n",
    "\n",
    "rating_tags = driver.find_elements(By.XPATH,'//*[@class=\"a-icon a-icon-star-small a-star-small-4 aok-align-bottom\"]')\n",
    "for i in rating_tags:\n",
    "    ra=i.text\n",
    "    Rating.append(ra)\n",
    "print(Rating[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dcdec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e1f58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping price from the given page \n",
    "\n",
    "price_tags = driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in price_tags:\n",
    "    pr=i.text\n",
    "    Price.append(pr)\n",
    "print(Price[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907aec89",
   "metadata": {},
   "source": [
    "# Q6: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. Click on TopQuote\n",
    "3. Than scrap a)Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5dfe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4758b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the azquotes page on automated chrome browser \n",
    "\n",
    "driver.get(\"https://www.azquotes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade1e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b172add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping title from the given page \n",
    "\n",
    "q_tags = driver.find_elements(By.XPATH,'//*[@class=\"title\"]')\n",
    "for i in q_tags:\n",
    "    title=i.text\n",
    "    Q.append(title)\n",
    "print(Q[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992140c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Author=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaea9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Author from the given page \n",
    "\n",
    "A_tags = driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "for i in A_tags:\n",
    "    name=i.text\n",
    "    Author.append(name)\n",
    "print(Author[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3605422",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOQ=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643c6987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping type of quote from the given page \n",
    "\n",
    "AOQ_tags = driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "for i in AOQ_tags:\n",
    "    name=i.text\n",
    "    TOQ.append(name)\n",
    "print(TOQ[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22beaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb02de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=9\n",
    "for page in range(start,end):\n",
    "    qp=driver.find_elements(By.XPATH,'//*[@class=\"title\"]')\n",
    "    for i in qp:\n",
    "        Q.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//li[@class=\"next\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "Q[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21128222",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de7da39",
   "metadata": {},
   "outputs": [],
   "source": [
    "Author=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5e6664",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=9\n",
    "for page in range(start,end):\n",
    "    A_tag=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    for i in A_tag:\n",
    "        Author.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//li[@class=\"next\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "Author[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd0fa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3583da",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOQ=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e8df8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=9\n",
    "for page in range(start,end):\n",
    "    TO_tag=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for i in TO_tag:\n",
    "        TOQ.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//li[@class=\"next\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "TOQ[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66514fde",
   "metadata": {},
   "source": [
    "# Q7: Write a python program to display list of respected former Prime Ministers of India (i.e. Name,\n",
    "Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/general-knowledge/list-of\u0002all-prime-ministers-of-india-1473165149-1\n",
    "scrap the mentioned data and make the DataFram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dbd47046",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34b8970",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.jagranjosh.com/general-knowledge/list-of-all-prime-ministers-of-india-1473165149-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15124cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d2629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acfd1a5b",
   "metadata": {},
   "source": [
    "# Q8: Write a python program to display list of 50 Most expensive cars in the world\n",
    "(i.e. Car name and Price) from https://www.motor1.com/\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.motor1.com/\n",
    "2. Then You have to type in the search bar ’50 most expensive cars’\n",
    "3. Then click on 50 most expensive carsin the world..\n",
    "4. Then scrap thementioned data and make the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fd172c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6aaf8b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.motor1.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f1643d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand= driver.find_element(By.XPATH,'//body[@class=\"not-touch m1-skin-layout lightHeader hangingHeader no-lazyload-banner adgrid-ad-target\"]')\n",
    "brand.send_keys('50 most expensive cars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5568f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
