{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5353512d",
   "metadata": {},
   "source": [
    "# WEB SCRAPING – ASSIGNMENT 4\n",
    "• Read all the problem statements, notes carefully and scrape the required data using any web scraping tool of \n",
    "your choice. \n",
    "• You have to handle commonly occurring EXCEPTIONS by using exception handling programing. To get \n",
    "information about selenium Exceptions. You may visit following links: \n",
    "1. https://selenium-python.readthedocs.io/api.html\n",
    "2. https://www.guru99.com/exception-handling-selenium.html\n",
    "3. https://stackoverflow.com/questions/38022658/selenium-python-handling-no-such-element\u0002exception/38023345\n",
    "\n",
    "\n",
    "\n",
    "Q1.   Scrape the details of most viewed videos on YouTube from Wikipedia. Url \n",
    "= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: A)\n",
    "Rank \n",
    "B) Name \n",
    "C) Artist \n",
    "D) Upload date \n",
    "E) Views \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e3ef744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "\n",
    "import selenium \n",
    "import time \n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver \n",
    "\n",
    "\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "import requests\n",
    "\n",
    "from selenium.webdriver.common.by import By\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6a04936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to driver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27004746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# website url\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99da08b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create empty list \n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_date=[]\n",
    "Views=[]\n",
    "Data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6eccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_1 = driver.find_element(By.XPATH,'/html/body')\n",
    "search_1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129a5014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the data\n",
    "dt=driver.find_elements(By.XPATH, '//*[@id=\"mw-content-text\"]/div[1]/table[1]/tbody')\n",
    "for i in dt:\n",
    "    if i.text is None :\n",
    "        Data.append(\"--\") \n",
    "    else:\n",
    "        Data.append(i.text)\n",
    "print(len(Data),Data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fb3154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the Artist name\n",
    "ar=driver.find_elements(By.XPATH ,\"//*[@id='mw-content-text']/div[1]/table[1]/tbody/tr/td[2]\")\n",
    "for i in ar:\n",
    "    if i.text is None :\n",
    "        Artist.append(\"--\") \n",
    "    else:\n",
    "        Artist.append(i.text)\n",
    "print(len(Artist),Artist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71a0671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the views\n",
    "\n",
    "V=driver.find_elements(By.XPATH, \"//*[@id='mw-content-text']/div[1]/table[1]/tbody/tr/td[3]\")\n",
    "for i in V:\n",
    "    if i.text is None :\n",
    "        Views.append(\"--\") \n",
    "    else:\n",
    "        Views.append(i.text)\n",
    "print(len(Views),Views)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b9aaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the upload date \n",
    "\n",
    "ud=driver.find_elements(By.XPATH, \"//*[@id='mw-content-text']/div[1]/table[1]/tbody/tr/td[4]\")\n",
    "for i in ud:\n",
    "    if i.text is None :\n",
    "        Upload_date.append(\"--\") \n",
    "    else:\n",
    "        Upload_date.append(i.text)\n",
    "print(len(Upload_date),Upload_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2116aa56",
   "metadata": {},
   "source": [
    "# 2. Scrape the details team India’s international fixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/. \n",
    "You need to find following details: \n",
    "A) Series \n",
    "B) Place \n",
    "C) Date \n",
    "D) Time \n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59c72f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to driver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6fb01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# website url\n",
    "driver.get(\"https://www.bcci.tv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a67abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search the international \n",
    "search=driver.find_element(By.XPATH, '//li[@class=\"nav-item\"]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7296a7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search the fixture\n",
    "search2=driver.find_element(By.XPATH,'/html/body/header/div[3]/div[2]/ul/div[1]/a[2]')\n",
    "search2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ef8894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the empty list\n",
    "Series=[]\n",
    "place=[]\n",
    "date=[]\n",
    "time=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fecf610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrap the series \n",
    "\n",
    "sr=driver.find_elements(By.XPATH, '//div[@class=\"match-card-top\"]')\n",
    "for i in sr:\n",
    "    if i.text is None :\n",
    "        Series.append(\"--\") \n",
    "    else:\n",
    "        Series.append(i.text)\n",
    "print(len(Series),Series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f0c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrap the date\n",
    "\n",
    "DT=driver.find_elements(By.XPATH, '//div[@class=\"match-dates ng-binding\"]')\n",
    "for i in DT:\n",
    "    if i.text is None :\n",
    "        date.append(\"--\") \n",
    "    else:\n",
    "        date.append(i.text)\n",
    "print(len(date),date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36cc608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrap place or ground\n",
    "\n",
    "P=driver.find_elements(By.XPATH, '//div[@class=\"match-place ng-scope\"]')\n",
    "for i in P:\n",
    "    if i.text is None :\n",
    "        place.append(\"--\") \n",
    "    else:\n",
    "        place.append(i.text)\n",
    "print(len(place),place)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2981df46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrap the time\n",
    "\n",
    "T=driver.find_elements(By.XPATH, '//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for i in T:\n",
    "    if i.text is None :\n",
    "        time.append(\"--\") \n",
    "    else:\n",
    "        time.append(i.text)\n",
    "print(len(time),time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44761c11",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of State-wise GDP of India from statisticstime.com. \n",
    "Url = http://statisticstimes.com/ \n",
    "You have to find following details: A) Rank \n",
    "B) State \n",
    "C) GSDP(18-19)- at current prices \n",
    "D) GSDP(19-20)- at current prices \n",
    "E) Share(18-19) \n",
    "F) GDP($ billion) \n",
    "Note: - From statisticstimes home page you have to reach to economy page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfb5521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to driver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826bd58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# website url\n",
    "driver.get(\"http://statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0c5b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "economy_page = driver.find_element(By.XPATH, '//*[@id=\"top\"]/div[2]/div[2]/button') # Locating page for economy by xpath\n",
    "economy_page.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77df3ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_page = driver.find_element(By.XPATH, '//*[@id=\"top\"]/div[2]/div[2]/div/a[3]')  # Locating page for india economy by xpath\n",
    "ind_page.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f32816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists\n",
    "\n",
    "Rank=[]\n",
    "State=[]\n",
    "GSDP18_19=[]\n",
    "GSDP19_20=[]\n",
    "share18_19=[]\n",
    "GDP_billion=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916f8145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching gdp page\n",
    "gdp = driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')  \n",
    "gdp.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a19c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrap the Rank \n",
    "\n",
    "r=driver.find_elements(By.XPATH, \"//td[@class='data1']\")\n",
    "for i in r:\n",
    "    if i.text is None :\n",
    "        Rank.append(\"--\") \n",
    "    else:\n",
    "        Rank.append(i.text)\n",
    "print(len(Rank),Rank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defc9427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrap the state \n",
    "\n",
    "St=driver.find_elements(By.XPATH, \"//td[@class='name']\")\n",
    "for i in St:\n",
    "    if i.text is None :\n",
    "        State.append(\"--\") \n",
    "    else:\n",
    "        State.append(i.text)\n",
    "print(len(State),State)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211afa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrap the GDP_billion \n",
    "\n",
    "gdp=driver.find_elements(By.XPATH, \"//*[@id='table_id']/tbody/tr/td[6]\")\n",
    "for i in gdp:\n",
    "    if i.text is None :\n",
    "        GDP_billion.append(\"--\") \n",
    "    else:\n",
    "        GDP_billion.append(i.text)\n",
    "print(len(GDP_billion),GDP_billion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f860e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Share \n",
    "shr=driver.find_elements(By.XPATH, \"//*[@id='table_id']/tbody/tr/td[5]\")\n",
    "for i in shr:\n",
    "    if i.text is None :\n",
    "        share18_19.append(\"--\") \n",
    "    else:\n",
    "        share18_19.append(i.text)\n",
    "print(len(share18_19),share18_19)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bed940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the GSDP19_20\n",
    "shr=driver.find_elements(By.XPATH, \"//*[@id='table_id']/tbody/tr/td[4]\")\n",
    "for i in shr:\n",
    "    if i.text is None :\n",
    "        GSDP19_20.append(\"--\") \n",
    "    else:\n",
    "        GSDP19_20.append(i.text)\n",
    "print(len(GSDP19_20),GSDP19_20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbddd312",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the GSDP18_19\n",
    "shr=driver.find_elements(By.XPATH, \"//*[@id='table_id']/tbody/tr/td[8]\")\n",
    "for i in shr:\n",
    "    if i.text is None :\n",
    "        GSDP18_19.append(\"--\") \n",
    "    else:\n",
    "        GSDP18_19.append(i.text)\n",
    "print(len(GSDP18_19),GSDP18_19)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b70a7c",
   "metadata": {},
   "source": [
    "# 4. Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/ \n",
    "\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "\n",
    "A) Repository title \n",
    "\n",
    "\n",
    "B) Repository description \n",
    "\n",
    "\n",
    "C) Contributors count \n",
    "\n",
    "\n",
    "D) Language used\n",
    "\n",
    "\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4dfb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to driver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b54ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# website url\n",
    "driver.get(\"https://github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729c6fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore = driver.find_element(By.XPATH, '/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details')    \n",
    "explore.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3b761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending = driver.find_element(By.XPATH, '/html/body/div[1]/div[6]/main/div[1]/nav/div/a[3]')    \n",
    "trending.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92064606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Repositor_Name \n",
    "Repository_Name=[]\n",
    "RN=driver.find_elements(By.XPATH, \"//span[@class='text-normal']\")\n",
    "for i in RN:\n",
    "    if i.text is None :\n",
    "        Repository_Name.append(\"--\") \n",
    "    else:\n",
    "        Repository_Name.append(i.text)\n",
    "print(len(Repository_Name),Repository_Name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f309cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Description=[]\n",
    "#scraping the Description \n",
    "des=driver.find_elements(By.XPATH , '//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "for i in des:\n",
    "    if i.text is None :\n",
    "        Description.append(\"--\") \n",
    "    else:\n",
    "        Description.append(i.text)\n",
    "print(len(Description),Description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bd4b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Language \n",
    "Language_used=[]\n",
    "L=driver.find_elements(By.XPATH, \"//span[@itemprop='programmingLanguage']\")\n",
    "for i in L:\n",
    "    if i.text is None :\n",
    "        Language_used.append(\"NAN\") \n",
    "    else:\n",
    "        Language_used.append(i.text)\n",
    "print(len(Language_used),Language_used)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b708e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the count\n",
    "count=[]\n",
    "ml=driver.find_elements(By.XPATH, \"//a[@class='muted-link d-inline-block mr-3']\")\n",
    "for i in ml:\n",
    "    if i.text is None :\n",
    "        count.append(\"NAN\") \n",
    "    else:\n",
    "        count.append(i.text)\n",
    "print(len(count),count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a667ad68",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the \n",
    "following details: \n",
    "    \n",
    "    \n",
    "A) Song name\n",
    "\n",
    "\n",
    "B) Artist name\n",
    "\n",
    "\n",
    "C) Last week rank\n",
    "\n",
    "\n",
    "D) Peak rank\n",
    "\n",
    "\n",
    "E) Weeks on board\n",
    "\n",
    "\n",
    " Note: - From the home page you have to click on the charts option then hot 100-page link through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ff4c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to driver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efde002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# website url\n",
    "driver.get(\"https:/www.billboard.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626b08c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Song_Name =[]\n",
    "Singer=[]\n",
    "rank=[]\n",
    "Last_Week=[]\n",
    "Weeks_on_board=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b264b2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "top100 = driver.find_element(By.XPATH , '//*[@id=\"root\"]/div[2]/div[2]/nav/ul/li[3]')      \n",
    "top100.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea904ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Rank \n",
    "rb=driver.find_elements(By.XPATH, \"//div[@class='chart-element__meta text--center color--secondary text--peak']\")\n",
    "for i in rb:\n",
    "    if i.text is None :\n",
    "        rank.append(\"--\") \n",
    "    else:\n",
    "        rank.append(i.text)\n",
    "print(len(rank),rank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f923c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Song_Name \n",
    "son=driver.find_elements(By.XPATH, \"//span[@class='chart-element__information__song text--truncate color--primary']\")\n",
    "for i in son:\n",
    "    if i.text is None :\n",
    "        Song_Name.append(\"--\") \n",
    "    else:\n",
    "        Song_Name.append(i.text)\n",
    "print(len(Song_Name),Song_Name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec762648",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Singer \n",
    "sin=driver.find_elements(By.XPATH, \"//span[@class='chart-element__information__artist text--truncate color--secondary']\")\n",
    "for i in sin:\n",
    "    if i.text is None :\n",
    "        Singer.append(\"--\") \n",
    "    else:\n",
    "        Singer.append(i.text)\n",
    "print(len(Singer),Singer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc77ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Last_Week Rank \n",
    "lwr=driver.find_elements(By.XPATH, \"//div[@class='chart-element__meta text--center color--secondary text--last']\")\n",
    "for i in lwr:\n",
    "    if i.text is None :\n",
    "        Last_Week.append(\"--\") \n",
    "    else:\n",
    "        Last_Week.append(i.text)\n",
    "print(len(Last_Week),Last_Week)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d08b86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Weeks_on_board \n",
    "wob=driver.find_elements(By.XPATH, \"//div[@class='chart-element__meta text--center color--secondary text--week']\")\n",
    "for i in wob:\n",
    "    if i.text is None :\n",
    "        Weeks_on_board.append(\"--\") \n",
    "    else:\n",
    "        Weeks_on_board.append(i.text)\n",
    "print(len(Weeks_on_board),Weeks_on_board)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6478c17",
   "metadata": {},
   "source": [
    "# 6. Scrape the details of Highest selling novels. \n",
    "\n",
    "\n",
    "A) Book name \n",
    "\n",
    "\n",
    "B) Author name \n",
    "\n",
    "\n",
    "C) Volumes sold \n",
    "\n",
    "\n",
    "D) Publisher \n",
    "\n",
    "\n",
    "E) Genre \n",
    "\n",
    "\n",
    "Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969c0f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to driver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee534325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# website url\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1715f8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists\n",
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26122d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Book_name \n",
    "bname=driver.find_elements(By.XPATH, \"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[2]\")\n",
    "for i in bname:\n",
    "    if i.text is None :\n",
    "        Book_name.append(\"--\") \n",
    "    else:\n",
    "        Book_name.append(i.text)\n",
    "print(len(Book_name),Book_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e149be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Author_name \n",
    "Auth=driver.find_elements(By.XPATH, \"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[3]\")\n",
    "for i in Auth:\n",
    "    if i.text is None :\n",
    "        Author_name.append(\"--\") \n",
    "    else:\n",
    "        Author_name.append(i.text)\n",
    "print(len(Author_name),Author_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31508a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Genre \n",
    "gen=driver.find_elements(By.XPATH, \"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[6]\")\n",
    "for i in gen:\n",
    "    if i.text is None :\n",
    "        Genre.append(\"--\") \n",
    "    else:\n",
    "        Genre.append(i.text)\n",
    "print(len(Genre),Genre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06375ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Publisher \n",
    "pub=driver.find_elements(By.XPATH, \"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[5]\")\n",
    "for i in pub:\n",
    "    if i.text is None :\n",
    "        Publisher.append(\"--\") \n",
    "    else:\n",
    "        Publisher.append(i.text)\n",
    "print(len(Publisher),Publisher)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23f799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Volumes_sold \n",
    "vs=driver.find_elements(By.XPATH, \"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[4]\")\n",
    "for i in vs:\n",
    "    if i.text is None :\n",
    "        Volumes_sold.append(\"--\") \n",
    "    else:\n",
    "        Volumes_sold.append(i.text)\n",
    "print(len(Volumes_sold),Volumes_sold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1b6dda",
   "metadata": {},
   "source": [
    "# 7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "\n",
    "\n",
    "Url = https://www.imdb.com/list/ls512407256/ You have \n",
    "\n",
    "    \n",
    "to find the following details: \n",
    "\n",
    "    \n",
    "A) Name \n",
    "\n",
    "\n",
    "B) Year span \n",
    "\n",
    "\n",
    "C) Genre \n",
    "\n",
    "\n",
    "D) Run time \n",
    "\n",
    "\n",
    "E) Ratings \n",
    "\n",
    "\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611272af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to driver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6137b577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# website url\n",
    "driver.get(\"https://www.imdb.com/list/ls512407256/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c684c839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists\n",
    "Name=[]\n",
    "Year_span=[]\n",
    "Genres=[]\n",
    "Run_time=[]\n",
    "Ratings=[]\n",
    "Votes=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c77cccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Name \n",
    "mname=driver.find_elements(By.XPATH, \"//div[@class='lister-item-content']/h3/a\")\n",
    "for i in mname:\n",
    "    if i.text is None :\n",
    "        Name.append(\"--\") \n",
    "    else:\n",
    "        Name.append(i.text)\n",
    "print(len(Name),Name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b9f4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Year_span \n",
    "ys=driver.find_elements(By.XPATH, \"//span[@class='lister-item-year text-muted unbold']\")\n",
    "for i in ys:\n",
    "    if i.text is None :\n",
    "        Year_span.append(\"--\") \n",
    "    else:\n",
    "        Year_span.append(i.text)\n",
    "print(len(Year_span),Year_span)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff4de58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Genres \n",
    "gnr=driver.find_elements(By.XPATH, \"//p[@class='text-muted text-small']/span[5]\")\n",
    "for i in gnr:\n",
    "    if i.text is None :\n",
    "        Genres.append(\"--\") \n",
    "    else:\n",
    "        Genres.append(i.text)\n",
    "print(len(Genres),Genres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b331450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Run_time \n",
    "rt=driver.find_elements(By.XPATH, \"//p[@class='text-muted text-small']/span[3]\")\n",
    "for i in rt:\n",
    "    if i.text is None :\n",
    "        Run_time.append(\"--\") \n",
    "    else:\n",
    "        Run_time.append(i.text)\n",
    "print(len(Run_time),Run_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631dffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Ratings \n",
    "rate=driver.find_elements(By.XPATH, \"//div[@class='ipl-rating-star small']/span[2]\")\n",
    "for i in rate:\n",
    "    if i.text is None :\n",
    "        Ratings.append(\"--\") \n",
    "    else:\n",
    "        Ratings.append(i.text)\n",
    "print(len(Ratings),Ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbacc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Votes \n",
    "v=driver.find_elements(By.XPATH , \"//div[@class='lister-item-content']/p[4]/span[2]\")\n",
    "for i in v:\n",
    "    if i.text is None :\n",
    "        Votes.append(\"--\") \n",
    "    else:\n",
    "        Votes.append(i.text)\n",
    "print(len(Votes),Votes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9411a788",
   "metadata": {},
   "source": [
    "# 8. Details of Datasets from UCI machine learning repositories. \n",
    "\n",
    "\n",
    "Url = https://archive.ics.uci.edu/ You \n",
    "\n",
    "\n",
    "have to find the following details: \n",
    "\n",
    "A) Dataset name \n",
    "\n",
    "B) Data type \n",
    "\n",
    "C) Task \n",
    "\n",
    "D) Attribute type \n",
    "\n",
    "E) No of instances \n",
    "\n",
    "F) No of attribute \n",
    "\n",
    "G) Year \n",
    " \n",
    "    Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c807cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464cbfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# website url\n",
    "driver.get(\"https://archive.ics.uci.edu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89816bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_Name=[]\n",
    "Data_Type=[]\n",
    "Task=[]\n",
    "Attribute_Type=[]\n",
    "No_of_Instances=[]\n",
    "No_of_Attribute=[]\n",
    "Year=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f66470",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_1 = driver.find_element(By.XPATH , '/html/body/div/div[1]/div[1]/header/div[2]/div[2]')   \n",
    "search_1.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa4f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Dataset_Name \n",
    "dname=driver.find_elements(By.XPATH, \"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[1]/table/tbody/tr/td[2]/p/b/a\")\n",
    "for i in dname:\n",
    "    if i.text is None :\n",
    "        Dataset_Name.append(\"--\") \n",
    "    else:\n",
    "        Dataset_Name.append(i.text)\n",
    "print(len(Dataset_Name),Dataset_Name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
