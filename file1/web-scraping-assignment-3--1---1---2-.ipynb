{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "631ce8d7",
   "metadata": {},
   "source": [
    "# WEB SCRAPING-ASSIGNMENT3\n",
    " \n",
    "Instructions: \n",
    "• All questions are compulsory. \n",
    "\n",
    "• In each of the questions you have to automate the process. You do not have to click on any button, click any \n",
    "clickable element, enter keywords in search boxes manually. Each process has to be performed via coding.\n",
    "\n",
    "• Q1 and Q2 are connected questions i.e. after attempting Q1 proceed to Q2. Do not write whole code from \n",
    "beginning for Q2. \n",
    "\n",
    "• You may use any web scraping library and tools. \n",
    "\n",
    "• The question can be attempted in various ways; the correctness of question depends on the output. \n",
    "\n",
    "• If you encounter any Null values during scraping, you may replace it by hyphen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d969094e",
   "metadata": {},
   "source": [
    "# Exercise: \n",
    "1. Write a python program which searches all the product under a particular product from www.amazon.in. The \n",
    "product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for \n",
    "guitars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c82458c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "\n",
    "import selenium \n",
    "import time \n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver \n",
    "\n",
    "\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "import requests\n",
    "\n",
    "from selenium.webdriver.common.by import By\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76fe8174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to driver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d364a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# website url\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f4354bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search bar selection \n",
    "search_bar=driver.find_element(By.ID,\"twotabsearchtextbox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ad4d07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what would you like to search today?\n",
      "guitar\n"
     ]
    }
   ],
   "source": [
    "# Take input from user \n",
    "print(\"what would you like to search today?\")\n",
    "search_for=input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d4dad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send the input taken \n",
    "search_bar.clear()\n",
    "search_bar.send_keys(search_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "11894959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on search button\n",
    "search_button=driver.find_element(By.ID,\"nav-search-submit-button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6095c060",
   "metadata": {},
   "source": [
    "# 2. In the above question, now scrape the following details of each product listed in first 3 pages of your search \n",
    "results and save it in a data frame and csv. In case if any product has less than 3 pages in search results then \n",
    "scrape all the products available under that product name. Details to be scraped are: \"Brand \n",
    "Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and \n",
    "“Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9520d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the urls of all products\n",
    "product_urls=[]\n",
    "start=0\n",
    "end=2\n",
    "\n",
    "for page in range(start, end):\n",
    "    url=driver.find_elements(By.XPATH,'//span[@class=\"a-size-base-plus a-color-base a-text-normal\"]')\n",
    "    for i in url:\n",
    "        product_urls.append(i.get_attribute(\"href\"))\n",
    "    nxt_button=driver.find_element(By.XPATH,'//a[@class=\"s-pagination-item s-pagination-next s-pagination-button s-pagination-separator\"]')\n",
    "    nxt_button.click()\n",
    "    time.sleep(2)\n",
    "      \n",
    "    \n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d54bf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(product_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e0a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "53ea01a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list=[]\n",
    "title_list=[]\n",
    "price_list=[]\n",
    "return_exchange_list=[]\n",
    "expected_delivery_list=[]\n",
    "availability_list=[]\n",
    "product_url=[]\n",
    "details_list=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c2dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to each items url to fetch data\n",
    "\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    # brand \n",
    "    try:\n",
    "        brand=driver.find_element(By.XPATH,'//span[@class=\"a-size-base po-break-word\"]')\n",
    "        brand_list.append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        brand_list.append(\"--\")\n",
    "    # Scrap tittle for each item \n",
    "    try:\n",
    "        title=driver.find_element(By.XPATH,'//span[@class=\"a-size-large product-title-word-break\"]')\n",
    "        title_list.append(title.text)\n",
    "    except NoSuchElementException:\n",
    "        title_list.append(\"--\")\n",
    "    # Scrap Price \n",
    "    try:\n",
    "        price=driver.find_element(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "        price_list.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        price_list.append(\"-\")  \n",
    "    # Return/Exchange\n",
    "    try:\n",
    "        returns=driver.find_element(By.XPATH,'//span[@class=\"a-size-small a-color-link a-text-normal\"]')\n",
    "        return_exchange_list.append(returns.text)\n",
    "    except NoSuchElementException:\n",
    "        return_exchange_list.append(\"-\")  \n",
    "    # Availability\n",
    "    try:\n",
    "        expected=driver.find_element(By.XPATH,'//span[@class=\"a-text-bold\"]')\n",
    "        expected_delivery_list.append(expected.text)\n",
    "    except NoSuchElementException:\n",
    "        expected_delivery_list.append(\"-\")  \n",
    "    # Details \n",
    "    try:\n",
    "        detail=driver.find_element(By.XPATH,'//div[@id=\"feature-bullets\"]')\n",
    "        details_list.append(detail.text)\n",
    "    except NoSuchElementException:\n",
    "        details_list.append(\"-\") \n",
    "    # product url\n",
    "    try:\n",
    "        url=driver.find_element(By.XPATH,'//span[@class=\"a-size-base-plus a-color-base a-text-normal\"]')\n",
    "        product_url.append(url.text)\n",
    "    except NoSuchElementException:\n",
    "        product_url.append(\"-\") \n",
    "\n",
    "print(brand_list[0:12]) \n",
    "print(title_list[0:12])\n",
    "print(price_list[0:12])\n",
    "print(return_exchange_list[0:12])\n",
    "print(expected_delivery_list[0:12])\n",
    "print(availability_list[0:12])\n",
    "print(product_url[0:12])\n",
    "print(details_list[0:12])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e8d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the length of all lists are equal\n",
    "\n",
    "print(len(brand_list))\n",
    "print(len(title_list))\n",
    "print(len(price_list))\n",
    "print(len(return_exchange_list))\n",
    "print(len(expected_delivery_list))\n",
    "print(len(availability_list))\n",
    "print(len(product_url))\n",
    "print(len(details_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017ff188",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#creating data frame\n",
    "df=pd.DataFrame({})\n",
    "df['Brand']=brand_list\n",
    "df['Name of the product']=title_list\n",
    "df['Price']=price_list\n",
    "df['Return / Exchange']=return_exchange_list\n",
    "df['expected_delivery']=expected_delivery_list\n",
    "df['Availability']=availability_list\n",
    "df['Other details']=details_list\n",
    "df['Product Urls']=product_url\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a18cf490",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a04014f",
   "metadata": {},
   "source": [
    "# 3. Write a python program to access the search bar and search button on images.google.com and scrape 10 \n",
    "images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0825e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to driver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "721bbd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://images.google.com/?gws_rd=ssl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f2083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search for fruits\n",
    "search_bar=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/textarea')\n",
    "search_bar.send_keys(\"Fruits\")\n",
    "time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f6070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/button')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7147f1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(20):\n",
    "    driver.execute_script(\"window.scrollBy(0,100)\")\n",
    "img_urls=[]\n",
    "images=driver.find_elements(By.XPATH,'//div[@class=\"cC9Rib\"]')\n",
    "for image in images:\n",
    "    source=image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if (source[0:4]=='http'):\n",
    "            img_urls.append(source)\n",
    "            \n",
    "for i in range(len(img_urls)):\n",
    "    if i > 10:\n",
    "        breakBy.XPATH,\n",
    "    print(\"Downloading{0} of {1} images\".format(i, 10))\n",
    "    response=requests.get(img_urls[i])\n",
    "    file = open(r\"C:\\Assignements & HW\\Internship\"+str(i)+\".jpg\",\"wb\")\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3a41a4",
   "metadata": {},
   "source": [
    "# 4. Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com\n",
    "and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand \n",
    "Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”, \n",
    "“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the \n",
    "details is missing then replace it by “- “. Save your results in a dataframe and CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bb8814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to driver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf95e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: visit the google images page\n",
    "driver.get(\"http://www.flipkart.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0594b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search for fruits\n",
    "search_bar=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/div/input')\n",
    "search_bar.send_keys(\"Oneplus Nord, pixel 4A, etc.\")\n",
    "time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeedb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/button')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efbb117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the urls of all products\n",
    "product_urls=[]\n",
    "start=0\n",
    "end=1\n",
    "\n",
    "for page in range(start, end):\n",
    "    url=driver.find_elements(By.XPATH,'//div[@class=\"yKfJKb row\"]')\n",
    "    for i in url:\n",
    "        product_urls.append(i.get_attribute(\"href\"))\n",
    "    \n",
    "    time.sleep(2)\n",
    "      \n",
    "    \n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f583fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a795144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list=[]\n",
    "smartphone_name=[]\n",
    "color_list=[]\n",
    "ram_list=[]\n",
    "rom_list=[]\n",
    "primarycamera_list=[]\n",
    "displaysize_list=[]\n",
    "batterycapacity_list=[]\n",
    "price_list=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24faa237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to each items url to fetch data\n",
    "\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    # brand \n",
    "    try:\n",
    "        brand=driver.find_element(By.XPATH,'//div[@class=\"KzDlHZ\"]')\n",
    "        brand_list.append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        brand_list.append(\"-\")\n",
    "    # name\n",
    "    try:\n",
    "        name=driver.find_element(By.XPATH,'//div[@class=\"KzDlHZ\"]')\n",
    "        smartphone_name.append(name.text)\n",
    "    except NoSuchElementException:\n",
    "        smartphone_name.append(\"-\")\n",
    "    # Scrap color \n",
    "    try:\n",
    "        color=driver.find_element(By.XPATH,'//div[@class=\"KzDlHZ\"]')\n",
    "        color_list.append(color.text)\n",
    "    except NoSuchElementException:\n",
    "        color_list.append(\"-\")  \n",
    "    # Ram\n",
    "    try:\n",
    "        ram=driver.find_element(By.XPATH,'//li[@class=\"J+igdf\"]')\n",
    "        ram_list.append(ram.text)\n",
    "    except NoSuchElementException:\n",
    "        ram_list.append(\"-\")  \n",
    "    # rom\n",
    "    try:\n",
    "        rom=driver.find_element(By.XPATH,'//li[@class=\"J+igdf\"]')\n",
    "        rom_list.append(rom.text)\n",
    "    except NoSuchElementException:\n",
    "        rom_list.append(\"-\")  \n",
    "    # Primary camera \n",
    "    try:\n",
    "        pricamera=driver.find_element(By.XPATH,'//li[@class=\"J+igdf\"]')\n",
    "        primarycamera_list.append(pricamera.text)\n",
    "    except NoSuchElementException:\n",
    "        primarycamera_list.append(\"-\") \n",
    "    # display size\n",
    "    try:\n",
    "        ds=driver.find_element(By.XPATH,'//li[@class=\"J+igdf\"]')\n",
    "        displaysize_list.append(ds.text)\n",
    "    except NoSuchElementException:\n",
    "        displaysize_list.append(\"-\") \n",
    "        \n",
    "    # Battery capacity\n",
    "    try:\n",
    "        battery=driver.find_element(By.XPATH,'//li[@class=\"J+igdf\"]')\n",
    "        batterycapacity_list.append(battery.text)\n",
    "    except NoSuchElementException:\n",
    "        batterycapacity_list.append(\"-\") \n",
    "        \n",
    "    try:\n",
    "        price=driver.find_element(By.XPATH,'//li[@class=\"J+igdf\"]')\n",
    "        price_list.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        price_list.append(\"-\") \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f6bfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(brand_list[0:9])\n",
    "print(smartphone_name[0:9])\n",
    "print(color_list[0:9])\n",
    "print(ram_list[0:9])\n",
    "print(rom_list[0:9])\n",
    "print(primarycamera_list[0:9])\n",
    "print(displaysize_list[0:9])\n",
    "print(batterycapacity_list[0:9])\n",
    "print(price_list[0:9])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b70a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(brand_list)\n",
    "len(smartphone_name)\n",
    "len(color_list)\n",
    "len(ram_list)\n",
    "len(rom_list)\n",
    "len(primarycamera_list)\n",
    "len(displaysize_list)\n",
    "len(batterycapacity_list)\n",
    "len(price_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a589b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe \n",
    "df=pd.DataFrame({})\n",
    "df['Brand']=brand_list\n",
    "df['Smart Phone Name']=smartphone_name\n",
    "df['Color']=color_list\n",
    "df['RAM']=ram_list\n",
    "df['ROM']=rom_list\n",
    "df['Primary Camera']=primarycamera_list\n",
    "df['Display Size']=displaysize_list\n",
    "df['Battery Capacity']=batterycapacity_list\n",
    "df['Price']=price_list\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f42bba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dec8c0",
   "metadata": {},
   "source": [
    "# 5. Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1df9180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to driver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9b700ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: visit the google images page\n",
    "driver.get(\"https://www.google.com/maps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4ac3d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search for city\n",
    "search_bar=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/div[8]/div[3]/div[1]/div[1]/div/div[2]/form/input')\n",
    "search_bar.send_keys(\"Pune\")\n",
    "time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e00e3343",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'//div[@class=\"pzfvzf\"]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4195d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e8d09e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL Extracted :  https://www.google.com/maps/place/Pune,+Maharashtra/@18.5248706,73.6981482,11z/data=!3m1!4b1!4m6!3m5!1s0x3bc2bf2e67461101:0x828d43bf9d9ee343!8m2!3d18.5204303!4d73.8567437!16zL20vMDE1eTJx?entry=ttu\n",
      "Latitude=18.5248706, Longitude=73.6981482\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    url_string=driver.current_url\n",
    "    print(\"URL Extracted : \",url_string)\n",
    "    lat_lng = re.findall(r'@(.*)data', url_string)\n",
    "    if len(lat_lng):\n",
    "        la=lat_lng[0].split(\",\")\n",
    "        if len(la)>=2:\n",
    "            lat=la[0]\n",
    "            lon=la[1]\n",
    "        print(\"Latitude={}, Longitude={}\".format(lat,lon))\n",
    "except NoSuchElementException:\n",
    "    print(\"NO attribute\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4083958",
   "metadata": {},
   "source": [
    "# 6. Write a program to scrap all the available details of best gaming laptops from digit.in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289c2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to driver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370ce25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: visit the google images page\n",
    "driver.get(\"https://www.digit.in/top-products/best-gaming-laptops-40.html#msi-titan-gt77-hx-13vi-092in-13th-gen-core-i9-13980hx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e514cc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "operatingsystem=[]\n",
    "display=[]\n",
    "processor=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f2c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands=driver.find_elements(By.XPATH,'//div[@class=\"rh_gr_top_middle mb10 colored_rate_bar\"]')\n",
    "for i in brands:\n",
    "    b=i.text\n",
    "    brand.append(b)\n",
    "    \n",
    "operatingsystems=driver.find_elements(By.XPATH,'//span[@class=\"meta_v_value\"]')\n",
    "for i in operatingsystems:\n",
    "    o=i.text\n",
    "    operatingsystem.append(o)\n",
    "    \n",
    "displays=driver.find_elements(By.XPATH,'//span[@class=\"meta_v_value\"]')\n",
    "for i in displays:\n",
    "    d=i.text\n",
    "    display.append(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be193177",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(brands[0:10])\n",
    "print(operatingsystem[0:10])\n",
    "print(display[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb22d36",
   "metadata": {},
   "source": [
    "# 7. Write a python program to scrape the details for all billionaires from www.forbes.com. Details to be scrapped: \n",
    "“Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf917511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to driver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f4777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit the webpage\n",
    "driver.get(\"http://www.forbes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44035666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click hamburger link\n",
    "button = driver.find_element(By.CLASS_NAME, \"_69hVhdY4\")\n",
    "button.click()\n",
    "                             \n",
    "time.sleep(1)\n",
    "\n",
    "#click billionaires link\n",
    "button = driver.find_element(By.CLASS_NAME, \"mpBfVZz3\")\n",
    "button.click()\n",
    "                             \n",
    "time.sleep(3)\n",
    "\n",
    "#select world billioners \n",
    "world_billioners= driver.find_element(By.XPATH, \"//li[@class='TjJgrPSg _2bNo56RE secondary']/a\")\n",
    "world_billioners.click()\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11741a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lists\n",
    "rank = [] \n",
    "name = [] \n",
    "net_worth = [] \n",
    "age = []\n",
    "country = [] \n",
    "source = []\n",
    "industry = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385373bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping Billonaire info\n",
    "\n",
    "while(True):\n",
    "\n",
    "    ranks= driver.find_elements(By.XPATH, \"//div[@class='Table_rank___YBhk Table_dataCell__2QCve']\")\n",
    "    for i in ranks:\n",
    "        rank.append(i.text)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    names= driver.find_elements(By.XPATH, \"//div[@class='TableRow_row__L-0Km']//div[2]/div\")\n",
    "    for i in names:\n",
    "        name.append(i.text)\n",
    "    time.sleep(1)\n",
    "\n",
    "    net_worths= driver.find_elements(By.XPATH, \"//div[@class='TableRow_row__L-0Km']//div[3]/div\")\n",
    "    for i in net_worths:\n",
    "        net_worth.append(i.text)\n",
    "    time.sleep(1)     \n",
    "    \n",
    "    ages= driver.find_elements(By.XPATH, \"//div[@class='TableRow_row__L-0Km']//div[4]/div\")\n",
    "    for i in ages:\n",
    "        age.append(i.text)   \n",
    "    time.sleep(1)\n",
    "      \n",
    "    countries= driver.find_elements(By.XPATH, \"//div[@class='TableRow_row__L-0Km']//div[5]\")\n",
    "    for i in countries:\n",
    "        country.append(i.text)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    sources= driver.find_elements(By.XPATH, \"//div[@class='TableRow_row__L-0Km']//div[6]/div/span\")\n",
    "    for i in sources:\n",
    "        source.append(i.text)    \n",
    "    time.sleep(1)\n",
    "        \n",
    "    industries= driver.find_elements(By.XPATH, \"//div[@class='TableRow_row__L-0Km']//div[7]/div\")\n",
    "    for i in industries:\n",
    "        industry.append(i.text)    \n",
    "    time.sleep(1)   \n",
    "        \n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH, \"/html/body/div[1]/div[2]/div[3]/div[2]/div[2]/div[2]/div[2]/div[2]/div[1]/button[2]/div/span[1]\")\n",
    "        next_button.click()\n",
    "    except:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6743b2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74ed665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "061f824d",
   "metadata": {},
   "source": [
    "# 8. Write a program to extract at least 500 Comments, Comment upvote and time when comment was posted \n",
    "from any YouTube Video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f37f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to driver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5ef413",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.youtube.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f0fbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for search bar\n",
    "search_bar = driver.find_element(By.XPATH, '/html/body/ytd-app/div[1]/div/ytd-masthead/div[4]/div[2]/ytd-searchbox/form/div[1]/div[1]/input')\n",
    "search_bar.send_keys(\"uptown funk\") \n",
    "time.sleep(1)\n",
    "\n",
    "#clicking on search button\n",
    "search_btn = driver.find_element(By.ID, \"search-icon-legacy\")  \n",
    "search_btn.click()\n",
    "time.sleep(3)\n",
    "\n",
    "#clicking on first video\n",
    "link_click = driver.find_element(By.XPATH, \"//a[@class='yt-simple-endpoint style-scope ytd-video-renderer']\")\n",
    "link_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef0404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scroll to load comments\n",
    "for _ in range(1000):\n",
    "    driver.execute_script(\"window.scrollBy(0,5000)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7c4c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lists\n",
    "comment = []\n",
    "comment_time = []\n",
    "up_vote = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1357e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape comments\n",
    "comments = driver.find_elements(By.ID, \"content-text\")\n",
    "for i in comments:\n",
    "    if i.text is None:\n",
    "        comment.append(\"--\")\n",
    "    else:\n",
    "        comment.append(i.text)\n",
    "time.sleep(5)\n",
    "\n",
    "# scrape time when comment was posted\n",
    "times = driver.find_elements(By.XPATH, \"//a[contains(text(),'ago')]\")\n",
    "for i in times:\n",
    "    comment_time.append(i.text)\n",
    "\n",
    "for i in range(0,len(comment_time),2):\n",
    "    comment_time.append(comment_time[i])\n",
    "time.sleep(5)\n",
    "    \n",
    "# scrape the comment likes\n",
    "up = driver.find_elements(By.XPATH, \"//span[@class='style-scope ytd-comment-action-buttons-renderer']\")\n",
    "for i in up:\n",
    "    up_vote.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398c85ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrame\n",
    "df = pd.DataFrame({'Comment':comment[0:500],\n",
    "                'Comment Time':comment_time[0:500],\n",
    "                'Up Vote':up_vote[0:500]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7175c582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7905e5d3",
   "metadata": {},
   "source": [
    "# 9. Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in \n",
    "“London” location. You have to scrape hostel name, distance from city centre, ratings, total reviews, overall \n",
    "reviews, privates from price, dorms from price, facilities and property description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2173afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to driver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f3199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the webpage\n",
    "driver.get(\"https://www.hostelworld.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7af0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the location search bar\n",
    "search = driver.find_element(By.XPATH, \"/html/body/div[3]/div/div/div[2]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[2]/input\")\n",
    "search.send_keys(\"London\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "#select london\n",
    "london = driver.find_element(By.XPATH, '//*[@id=\"3\"]/button/div[2]')\n",
    "london.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# do click in search button\n",
    "search_btn = driver.find_element(By.XPATH, '//*[@id=\"__layout\"]/div/div[2]/div[2]/div[2]/div/div/div/div[5]/button')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c34f3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lists\n",
    "name = []\n",
    "distance = []\n",
    "rate = []\n",
    "total_reviews = []\n",
    "overall_review = []\n",
    "private = []\n",
    "dorm = []\n",
    "property_description = []\n",
    "url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d324a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape data\n",
    "while True:\n",
    "    urls = driver.find_elements(By.XPATH, \"//div[@class='property-card']/a\")\n",
    "    for u in urls:\n",
    "        url.append(u.get_attribute(\"href\"))\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    names = driver.find_elements(By.XPATH, \"//div[@class='property-name']\")\n",
    "    for n in names:\n",
    "        name.append(n.text)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    try:\n",
    "        dis = driver.find_elements(By.XPATH, '//*[@class=\"property-card\"]/a/a/div[2]/div[3]')\n",
    "        for d in dis:\n",
    "            distance.append(d.text)\n",
    "            time.sleep(1)\n",
    "    except NoSuchElementException:\n",
    "        distance.append('-')\n",
    "        time.sleep(1)\n",
    "\n",
    "    t_review = driver.find_elements(By.XPATH, '//*[@class=\"property-card\"]/a/a/div[2]/div[2]/div/div[2]/span')\n",
    "    for r in t_review:\n",
    "        if r.text.strip() == '':\n",
    "            dorm.append('-')\n",
    "        else:\n",
    "            dorm.append(r.text)\n",
    "        time.sleep(1)\n",
    "\n",
    "    try:\n",
    "        review = driver.find_elements(By.XPATH, '//*[@class=\"property-card\"]/a/a/div[2]/div[2]/div/div[1]/div[1]/span')\n",
    "        for o_r in review:\n",
    "            overall_review.append(o_r.text)\n",
    "            time.sleep(1)\n",
    "    except NoSuchElementException:\n",
    "        overall_review.append('-')\n",
    "        time.sleep(1)\n",
    "\n",
    "    privates = driver.find_elements(By.XPATH, '//div[@class=\"property-card\"]/a/a/div[2]/div[5]/div/div[1]')\n",
    "    for p in privates:\n",
    "        if p.text.strip() == '':\n",
    "            private.append('-')\n",
    "        else:\n",
    "            private.append(p.text)\n",
    "        time.sleep(1)\n",
    "\n",
    "    dorms = driver.find_elements(By.XPATH, '//*[@class=\"property-card\"]/a/a/div[2]/div[5]/div/div[2]/div[2]/strong')\n",
    "    for do in dorms:\n",
    "        if do.text.strip() == '':\n",
    "            dorm.append('-')\n",
    "        else:\n",
    "            dorm.append(do.text)\n",
    "        time.sleep(1)\n",
    "\n",
    "    rates = driver.find_elements(By.XPATH, '//*[@class=\"property-card\"]/a/a/div[2]/div[2]/div/div[1]/div[2]')\n",
    "    for ra in rates:\n",
    "        if ra.text.strip() == '':\n",
    "            rate.append('-')\n",
    "        else:\n",
    "            rate.append(ra.text)\n",
    "        time.sleep(1)\n",
    "\n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH, '//*[@id=\"__layout\"]/div/div[2]/div[2]/div[2]/div[1]/div/div/div/div/div[3]/div/button[2]')\n",
    "        next_button.click()\n",
    "        time.sleep(4)\n",
    "    except:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300c285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape property description\n",
    "for ur in url:\n",
    "    driver.get(ur)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        pd = driver.find_element(By.XPATH, '//*[@id=\"__layout\"]/div/div[2]/section/div[6]/div/div[2]/div/div/div[2]')\n",
    "        property_description.append(pd.text)\n",
    "    except NoSuchElementException:\n",
    "        property_description.append('-')\n",
    "    except:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0c5cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Hostel Name': name,\n",
    "    'Distance from city centre': distance,\n",
    "    'Overall Review': overall_review,\n",
    "    'Total Reviews': total_reviews,\n",
    "    'Privates From Price': private,\n",
    "    'Dorms From Price': dorm,\n",
    "    'Rating': rate,\n",
    "    'Property Description': property_description\n",
    "})\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
